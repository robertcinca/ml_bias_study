---
{
    "batch_size": [128, 256],
    "epochs": [10],
    "optimizer": [
        # "SGD",
        # "RMSprop",
        # "Adagrad",
        # "Adadelta",
        "Adam",
        # "Adamax",
        # "Nadam"
    ],
    "init_mode": [
        # "uniform",
        # "lecun_uniform",
        # "normal",
        # "zero",
        # "glorot_normal",
        # "glorot_uniform",
        # "he_normal",
        "he_uniform",
    ],
    "activation": [
        # "softmax",
        # "softplus",
        # "softsign",
        "relu",
        # "tanh",
        # "sigmoid",
        # "hard_sigmoid",
        # "linear",
    ],
    "weight_constraint": [0, 1, 2, 3],
    "dropout_rate": [0.001, 0.01, 0.1],
    "neurons": [16, 32, 64],
    "hidden_layers": [1, 2, 3],
}
# {
#     "batch_size": [128],
#     "epochs": [15],
#     "optimizer": [
#         "SGD",
#         "RMSprop",
#         # "Adagrad",
#         # "Adadelta",
#         "Adam",
#         # "Adamax",
#         "Nadam"
#     ],
#     "init_mode": [
#         "uniform",
#         "lecun_uniform",
#         "normal",
#         # "zero",
#         # "glorot_normal",
#         "glorot_uniform",
#         # "he_normal",
#         "he_uniform",
#     ],
#     "activation": [
#         "softmax",
#         # "softplus",
#         # "softsign",
#         "relu",
#         "tanh",
#         "sigmoid",
#         # "hard_sigmoid",
#         "linear",
#     ],
#     "weight_constraint": [0, 1, 2],
#     "dropout_rate": [0.1, 0.2, 0.3],
#     "neurons": [64, 128],
#     "hidden_layers": [3, 4, 5],
# }
# {
#     "batch_size": [8, 16, 32, 64, 128, 256, 512],
#     "epochs": [5, 10, 15, 20],
#     "optimizer": [
#         "SGD",
#         "RMSprop",
#         "Adagrad",
#         "Adadelta",
#         "Adam",
#         "Adamax",
#         "Nadam"
#     ],
#     "init_mode": [
#         "uniform",
#         "lecun_uniform",
#         "normal",
#         "zero",
#         "glorot_normal",
#         "glorot_uniform",
#         "he_normal",
#         "he_uniform",
#     ],
#     "activation": [
#         "softmax",
#         "softplus",
#         "softsign",
#         "relu",
#         "tanh",
#         "sigmoid",
#         "hard_sigmoid",
#         "linear",
#     ],
#     "weight_constraint": [0, 1, 2, 3, 4, 5],
#     "dropout_rate": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
#     "neurons": [8, 16, 32, 64, 128],
#     "hidden_layers": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
# }
